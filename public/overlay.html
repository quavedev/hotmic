<!DOCTYPE html>
<html>

<head>
  <meta charset="UTF-8">
  <title>Recording</title>
  <style>
    /* Base styles */
    body {
      margin: 0;
      padding: 0;
      background-color: transparent;
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, sans-serif;
      user-select: none;
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100vh;
      width: 100vw;
      overflow: hidden; /* Prevent scrolling */
    }

    /* Main container */
    .overlay-container {
      width: 170px;
      height: 170px;
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      color: white;
      text-align: center;
      -webkit-app-region: drag; /* Make draggable */
      cursor: move; /* Show move cursor */
      overflow: hidden; /* Prevent content from spilling out */
    }

    /* Square background */
    .blob-background {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      border-radius: 8px; /* Slight rounding on corners */
      background: rgba(0, 0, 0, 0.7);
      backdrop-filter: blur(5px);
      -webkit-backdrop-filter: blur(5px);
      z-index: -1;
      transform-origin: center;
      transition: transform 0.2s ease-out;
      box-shadow: 0 2px 10px rgba(0, 0, 0, 0.3);
      border: none;
    }

    /* Reactive blob */
    .reactive-blob {
      position: absolute;
      top: 10%;
      left: 10%;
      width: 80%;
      height: 80%;
      border-radius: 50%;
      background: radial-gradient(circle at center,
          rgba(75, 0, 130, 0.3) 0%,
          rgba(0, 180, 216, 0.3) 50%,
          rgba(0, 0, 0, 0) 70%);
      filter: blur(4px);
      z-index: -1;
      animation: pulse 3s infinite alternate;
      transform-origin: center;
    }

    /* Outer glow effect */
    .outer-glow {
      position: absolute;
      top: -20%;
      left: -20%;
      width: 140%;
      height: 140%;
      border-radius: 50%;
      background: radial-gradient(circle at center,
          rgba(64, 224, 208, 0.12) 0%,
          rgba(64, 224, 208, 0) 70%);
      z-index: -2;
      animation: breath 4s infinite alternate;
    }

    /* Particles container */
    .particles {
      position: absolute;
      top: 50%;
      left: 50%;
      width: 240px;
      height: 240px;
      transform: translate(-50%, -50%);
      overflow: visible;
      z-index: -1;
    }

    .particle {
      position: absolute;
      width: 3px;
      height: 3px;
      border-radius: 50%;
      background-color: rgba(255, 255, 255, 0.3);
      animation: float 3s infinite linear;
    }

    /* Recording indicator */
    .recording-indicator {
      width: 10px;
      height: 10px;
      border-radius: 50%;
      background-color: #ff3b30;
      margin-bottom: 8px;
      position: relative;
      z-index: 2;
    }

    .recording-indicator::before {
      content: '';
      position: absolute;
      top: -3px;
      left: -3px;
      right: -3px;
      bottom: -3px;
      background-color: rgba(255, 59, 48, 0.4);
      border-radius: 50%;
      animation: pulse 1.5s infinite;
      z-index: 1;
    }

    /* Audio level visualization */
    .audio-visualizer {
      width: 120px;
      height: 30px;
      margin: 8px 0;
      display: flex;
      justify-content: space-between;
      align-items: flex-end;
    }

    .audio-bar {
      width: 2px;
      height: 3px;
      background-color: rgba(64, 224, 208, 0.7);
      border-radius: 1px;
      transition: height 0.1s ease-out;
    }

    /* Status text */
    .status-message {
      font-size: 12px;
      margin: 4px 0;
      height: 16px;
      opacity: 0.9;
      text-shadow: 0 0 4px rgba(0, 0, 0, 0.8);
    }

    /* Timer display */
    .time-display {
      font-size: 24px;
      font-weight: 300;
      margin: 6px 0;
      text-shadow: 0 0 4px rgba(0, 0, 0, 0.8);
      letter-spacing: 1px;
    }

    /* Progress bar for transcription */
    .progress-container {
      width: 120px;
      height: 3px;
      background-color: rgba(255, 255, 255, 0.1);
      border-radius: 1.5px;
      margin: 8px 0;
      display: none;
      overflow: hidden;
      position: relative;
    }

    .progress-bar {
      height: 100%;
      width: 0%;
      background: linear-gradient(90deg, #40E0D0, #7F00FF);
      border-radius: 1.5px;
      transition: width 0.3s ease;
    }

    .progress-glow {
      position: absolute;
      top: 0;
      left: 0;
      width: 20px;
      height: 100%;
      background: linear-gradient(90deg, rgba(255, 255, 255, 0) 0%, rgba(255, 255, 255, 0.5) 50%, rgba(255, 255, 255, 0) 100%);
      animation: progressGlow 2s infinite linear;
      display: none;
    }

    /* Spinner */
    .spinner {
      display: none;
      width: 20px;
      height: 20px;
      border: 2px solid rgba(255, 255, 255, 0.1);
      border-radius: 50%;
      border-top-color: rgba(64, 224, 208, 0.7);
      animation: spin 1s linear infinite;
      margin-bottom: 8px;
    }

    /* Transcription icon */
    .transcription-icon {
      font-size: 20px;
      margin-bottom: 8px;
      display: none;
    }

    /* Control buttons */
    .controls {
      position: absolute;
      top: 6px;
      right: 6px;
      z-index: 10;
      -webkit-app-region: no-drag; /* Make buttons not draggable */
    }

    .control-button {
      width: 16px;
      height: 16px;
      border-radius: 4px;
      background-color: rgba(255, 255, 255, 0.2);
      color: white;
      font-size: 10px;
      display: flex;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      margin-bottom: 5px;
      transition: background-color 0.2s;
    }

    .control-button:hover {
      background-color: rgba(255, 255, 255, 0.4);
    }

    /* Animations */
    @keyframes pulse {
      0% {
        transform: scale(1);
        opacity: 1;
      }

      50% {
        transform: scale(1.05);
        opacity: 0.8;
      }

      100% {
        transform: scale(1);
        opacity: 1;
      }
    }

    @keyframes breath {
      0% {
        transform: scale(1);
        opacity: 0.5;
      }

      50% {
        transform: scale(1.1);
        opacity: 0.7;
      }

      100% {
        transform: scale(1);
        opacity: 0.5;
      }
    }

    @keyframes spin {
      0% {
        transform: rotate(0deg);
      }

      100% {
        transform: rotate(360deg);
      }
    }

    @keyframes progressGlow {
      0% {
        transform: translateX(-100%);
      }

      100% {
        transform: translateX(120px);
      }
    }

    @keyframes float {
      0% {
        transform: translateY(0) translateX(0);
        opacity: 0;
      }

      50% {
        opacity: 0.5;
      }

      100% {
        transform: translateY(-30px) translateX(8px);
        opacity: 0;
      }
    }

    /* States */
    .fade-out {
      animation: fadeOut 0.5s forwards;
    }

    @keyframes fadeOut {
      from {
        opacity: 1;
      }

      to {
        opacity: 0;
      }
    }

    .processing .blob-background {
      animation: processingPulse 2s infinite alternate;
    }

    @keyframes processingPulse {
      0% {
        transform: scale(1);
        background: rgba(0, 0, 0, 0.7);
      }

      100% {
        transform: scale(1.02);
        background: rgba(30, 30, 60, 0.7);
      }
    }
  </style>
</head>

<body>
  <div class="overlay-container">
    <!-- Square background -->
    <div class="blob-background"></div>

    <!-- Control buttons -->
    <div class="controls">
      <div class="control-button" id="closeButton">✕</div>
    </div>

    <!-- Visual elements -->
    <div class="recording-indicator"></div>
    <div class="spinner"></div>
    <div class="transcription-icon">✓</div>
    <div class="time-display">00:00</div>

    <!-- Audio visualization -->
    <div class="audio-visualizer" id="audioVisualizer"></div>

    <div class="status-message">Recording...</div>

    <!-- Progress visualization -->
    <div class="progress-container">
      <div class="progress-bar"></div>
      <div class="progress-glow"></div>
    </div>
  </div>

  <script>
    /**
     * HotMic Overlay
     *
     * Handles audio recording and displays visual feedback
     * for recording and transcription processes with reactive sci-fi effects.
     */

    // DOM elements
    const elements = {
      container: document.querySelector('.overlay-container'),
      blobBackground: document.querySelector('.blob-background'),
      recordingIndicator: document.querySelector('.recording-indicator'),
      statusMessage: document.querySelector('.status-message'),
      timeDisplay: document.querySelector('.time-display'),
      progressContainer: document.querySelector('.progress-container'),
      progressBar: document.querySelector('.progress-bar'),
      progressGlow: document.querySelector('.progress-glow'),
      spinner: document.querySelector('.spinner'),
      transcriptionIcon: document.querySelector('.transcription-icon'),
      audioVisualizer: document.getElementById('audioVisualizer')
    };

    // Application state
    const state = {
      isRecording: false,
      recordingStartTime: null,
      recordingInterval: null,
      audioContext: null,
      analyser: null,
      dataArray: null,
      mediaRecorder: null,
      audioData: [],
      audioBars: [],
      currentAudioLevel: 0,
      isCancelled: false
    };

    /**
     * UI Setup
     */

    // Create audio visualizer bars
    function createAudioVisualizer() {
      // Create 32 bars for the visualizer
      for (let i = 0; i < 32; i++) {
        const bar = document.createElement('div');
        bar.className = 'audio-bar';
        elements.audioVisualizer.appendChild(bar);
        state.audioBars.push(bar);
      }
    }

    /**
     * Recording functionality
     */

    // Update recording time display
    function updateTimeDisplay() {
      if (!state.recordingStartTime) return;

      const elapsed = Date.now() - state.recordingStartTime;
      const seconds = Math.floor((elapsed / 1000) % 60);
      const minutes = Math.floor((elapsed / 1000 / 60) % 60);

      elements.timeDisplay.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
    }

    // Calculate audio level from analyzer data
    function calculateAudioLevel(array) {
      let sum = 0;
      for (let i = 0; i < array.length; i++) {
        sum += array[i] / 255;
      }
      return sum / array.length;
    }

    // Update visualizer with audio levels
    function updateAudioVisualizer(levelData) {
      // Update each bar
      for (let i = 0; i < state.audioBars.length; i++) {
        // Add some randomness for a more natural look
        const barIndex = Math.floor(i * (levelData.length / state.audioBars.length));
        const level = levelData[barIndex] / 255;

        // Make middle bars taller for a natural curve
        const middleEffect = 1 + Math.sin((i / state.audioBars.length) * Math.PI) * 0.5;

        // Add some randomness
        const randomness = 0.7 + Math.random() * 0.6;

        const height = level * 35 * middleEffect * randomness;
        state.audioBars[i].style.height = `${Math.max(3, height)}px`;

        // Color based on height
        const hue = 180 + (level * 60); // cyan to purple
        state.audioBars[i].style.backgroundColor = `hsla(${hue}, 80%, 60%, 0.7)`;
      }
    }

    // Update visual effects based on audio level
    function updateVisualEffects(level) {
      const scaleFactor = 1 + level * 0.05;
      elements.blobBackground.style.transform = `scale(${scaleFactor})`;
    }

    // Monitor and display audio levels
    function monitorAudioLevel() {
      if (!state.analyser) return;

      state.analyser.getByteFrequencyData(state.dataArray);
      const level = calculateAudioLevel(state.dataArray);
      state.currentAudioLevel = level;

      // Update UI
      updateAudioVisualizer(state.dataArray);
      updateVisualEffects(level);

      // Send to main process
      window.api.sendAudioLevel(level);

      // Continue monitoring
      requestAnimationFrame(monitorAudioLevel);
    }

    // Start audio recording
    async function startRecording() {
      try {
        // Reset state
        state.isRecording = true;
        state.audioData = [];
        state.recordingStartTime = Date.now();

        // Update UI for recording state
        setRecordingUI();

        // Start timer
        state.recordingInterval = setInterval(updateTimeDisplay, 1000);
        updateTimeDisplay();

        // Get audio stream
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

        // Setup audio context for level monitoring
        setupAudioAnalyzer(stream);

        // Setup media recorder
        setupMediaRecorder(stream);

        // Start recording
        state.mediaRecorder.start();
      } catch (error) {
        elements.statusMessage.textContent = `Error: ${error.message}`;
      }
    }

    // Set up audio analyzer for level monitoring
    function setupAudioAnalyzer(stream) {
      state.audioContext = new AudioContext();
      const source = state.audioContext.createMediaStreamSource(stream);
      state.analyser = state.audioContext.createAnalyser();
      state.analyser.fftSize = 128;
      source.connect(state.analyser);
      state.dataArray = new Uint8Array(state.analyser.frequencyBinCount);

      // Start monitoring audio levels
      monitorAudioLevel();
    }

    // Set up media recorder
    function setupMediaRecorder(stream) {
      state.mediaRecorder = new MediaRecorder(stream);

      state.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          state.audioData.push(event.data);
        }
      };

      state.mediaRecorder.onstop = async () => {
        // If cancelled, don't process the audio
        if (state.isCancelled) {
          // Clean up
          stream.getTracks().forEach(track => track.stop());
          return;
        }

        // Convert to blob then to array buffer
        const blob = new Blob(state.audioData, { type: 'audio/wav' });
        const arrayBuffer = await blob.arrayBuffer();

        // Clean up
        stream.getTracks().forEach(track => track.stop());

        // Show processing UI
        setProcessingUI();

        // Send to main process
        window.api.sendAudioData(arrayBuffer);
      };
    }

    // Stop recording
    function stopRecording() {
      if (!state.isRecording || !state.mediaRecorder) return;

      state.isRecording = false;

      // Stop timer
      clearInterval(state.recordingInterval);

      // Stop media recorder
      if (state.mediaRecorder && state.mediaRecorder.state !== 'inactive') {
        state.mediaRecorder.stop();
      }

      // Stop audio context
      if (state.audioContext) {
        state.audioContext.close();
        state.audioContext = null;
        state.analyser = null;
      }
    }

    /**
     * UI State Management
     */

    // Set UI for recording state
    function setRecordingUI() {
      elements.container.classList.remove('processing');
      elements.recordingIndicator.style.display = 'block';
      elements.transcriptionIcon.style.display = 'none';
      elements.spinner.style.display = 'none';
      elements.progressContainer.style.display = 'none';
      elements.statusMessage.textContent = 'Recording...';
    }

    // Set UI for processing state
    function setProcessingUI() {
      elements.container.classList.add('processing');
      elements.recordingIndicator.style.display = 'none';
      elements.spinner.style.display = 'block';
      elements.progressContainer.style.display = 'block';
      elements.progressGlow.style.display = 'block';
      elements.statusMessage.textContent = 'Processing...';

      // Reset audio visualizer to small bars
      state.audioBars.forEach(bar => {
        bar.style.height = '3px';
        bar.style.backgroundColor = 'rgba(64, 224, 208, 0.4)';
      });
    }

    // Handle transcription progress updates
    function handleTranscriptionProgress(data) {
      const progressMap = {
        'start': { text: 'Starting...', progress: 10 },
        'api': { text: 'Sending to API...', progress: 30 },
        'receiving': { text: 'Receiving data...', progress: 70 },
        'complete': { text: 'Copied to clipboard!', progress: 100 },
        'error': { text: data.message, progress: 100 }
      };

      const progressInfo = progressMap[data.step] || { text: 'Processing...', progress: 50 };

      // Update UI
      elements.statusMessage.textContent = progressInfo.text;
      elements.progressBar.style.width = `${progressInfo.progress}%`;

      // For completion, show checkmark instead of spinner
      if (data.step === 'complete') {
        elements.spinner.style.display = 'none';
        elements.transcriptionIcon.style.display = 'block';
      }

      // For error, change colors
      if (data.step === 'error') {
        elements.progressBar.style.backgroundImage = 'linear-gradient(90deg, #ff3b30, #ff9500)';
      }
    }

    /**
     * Event Handlers
     */

    // External audio level update (from other windows)
    function handleExternalAudioLevel(level) {
      if (!state.isRecording) {
        // Update the visualizer with fake data based on the level
        const fakeData = new Uint8Array(64);
        for (let i = 0; i < fakeData.length; i++) {
          // Create a curve with higher values in the middle
          const centerEffect = Math.sin((i / fakeData.length) * Math.PI);
          fakeData[i] = Math.min(255, Math.floor(level * 255 * centerEffect * 1.5));
        }

        updateAudioVisualizer(fakeData);
        updateVisualEffects(level);
      }
    }

    // Register event listeners
    function registerEventListeners() {
      // Listen for start recording event
      window.api.onStartRecording(() => {
        startRecording();
      });

      // Listen for stop recording event
      window.api.onStopRecording(() => {
        stopRecording();
      });

      // Listen for audio level events (from other windows)
      window.api.onAudioLevel(handleExternalAudioLevel);

      // Listen for transcription progress
      window.api.onTranscriptionProgress(handleTranscriptionProgress);

      // Listen for cancellation
      window.api.onCancelTranscription(() => {
        state.isCancelled = true;
        if (state.mediaRecorder && state.mediaRecorder.state === 'recording') {
          state.mediaRecorder.stop();
        }
        state.audioData = [];
        if (state.recordingInterval) {
          clearInterval(state.recordingInterval);
        }
        state.isRecording = false;
      });
    }

    // Initialize the UI
    function initializeUI() {
      createAudioVisualizer();
    }

    // Initialize when DOM is loaded
    document.addEventListener('DOMContentLoaded', () => {
      initializeUI();
      registerEventListeners();
      
      // Add close button functionality
      document.getElementById('closeButton').addEventListener('click', () => {
        if (state.isRecording) {
          state.isCancelled = true;
          stopRecording();
          // Clean up audio context and recorder
          if (state.audioContext) {
            state.audioContext.close();
            state.audioContext = null;
            state.analyser = null;
          }
          if (state.mediaRecorder && state.mediaRecorder.state !== 'inactive') {
            state.mediaRecorder.stop();
          }
          // Reset state
          state.isRecording = false;
          state.audioData = [];
          clearInterval(state.recordingInterval);
        }
        window.api.openSettings();
      });
    });

    // Add keyboard shortcut listener
    document.addEventListener('keydown', (event) => {
      // Check for Cmd+, (comma) or Escape
      if ((event.metaKey || event.ctrlKey) && event.key === ',') {
        // Stop recording if active
        if (state.isRecording) {
          state.isCancelled = true;  // Set cancellation flag
          stopRecording();
          // Clean up audio context and recorder
          if (state.audioContext) {
            state.audioContext.close();
            state.audioContext = null;
            state.analyser = null;
          }
          if (state.mediaRecorder && state.mediaRecorder.state !== 'inactive') {
            state.mediaRecorder.stop();
          }
          // Reset state
          state.isRecording = false;
          state.audioData = [];
          clearInterval(state.recordingInterval);
        }
        // Open settings and close overlay
        window.api.openSettings();
      } else if (event.key === 'Escape') {
        // Handle escape key to cancel recording
        if (state.isRecording) {
          state.isCancelled = true;  // Set cancellation flag
          stopRecording();
          // Clean up audio context and recorder
          if (state.audioContext) {
            state.audioContext.close();
            state.audioContext = null;
            state.analyser = null;
          }
          if (state.mediaRecorder && state.mediaRecorder.state !== 'inactive') {
            state.mediaRecorder.stop();
          }
          // Reset state
          state.isRecording = false;
          state.audioData = [];
          clearInterval(state.recordingInterval);
        }
      }
    });
  </script>
</body>

</html>